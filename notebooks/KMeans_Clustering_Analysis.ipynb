{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Throughput Meta-Atom Defect Classification via K-Means Clustering\n",
    "\n",
    "**Automated defect detection in metasurface arrays using unsupervised machine learning**\n",
    "\n",
    "This notebook demonstrates a scalable pipeline for:\n",
    "1. Automated segmentation of metasurface arrays into individual meta-atoms\n",
    "2. Multi-dimensional feature extraction\n",
    "3. K-Means clustering for defect categorization\n",
    "4. Statistical validation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Publication-quality plot settings\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11,\n",
    "    'font.family': 'sans-serif',\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 13,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False\n",
    "})\n",
    "\n",
    "# Color palette for clusters\n",
    "CLUSTER_COLORS = ['#2ecc71', '#e74c3c', '#3498db', '#9b59b6', '#f39c12']\n",
    "CLUSTER_NAMES = ['Intact', 'Missing', 'Collapsed', 'Irregular']\n",
    "\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "if BASE_DIR.name == 'notebooks':\n",
    "    BASE_DIR = BASE_DIR.parent\n",
    "OUTPUT_DIR = BASE_DIR / \"Meta_Atoms\"\n",
    "FIGURES_DIR = BASE_DIR / \"figures\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Working directory: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Array Segmentation Pipeline\n",
    "\n",
    "Automated extraction of 441 meta-atom tiles from each 21x21 metasurface array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_array(image_path, output_dir, grid_size=21, tile_size=32, show_grid=False):\n",
    "    \"\"\"Extract individual meta-atom tiles from array image.\"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read {image_path}\")\n",
    "    \n",
    "    H, W = img.shape[:2]\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    array_dir = os.path.join(output_dir, base_name)\n",
    "    os.makedirs(array_dir, exist_ok=True)\n",
    "    \n",
    "    x_spacing = W / grid_size\n",
    "    y_spacing = H / grid_size\n",
    "    \n",
    "    tiles = []\n",
    "    for r in range(grid_size):\n",
    "        for c in range(grid_size):\n",
    "            cx = int((c + 0.5) * x_spacing)\n",
    "            cy = int((r + 0.5) * y_spacing)\n",
    "            x1, y1 = max(0, cx - tile_size), max(0, cy - tile_size)\n",
    "            x2, y2 = min(W, cx + tile_size), min(H, cy + tile_size)\n",
    "            \n",
    "            tile = img[y1:y2, x1:x2]\n",
    "            fname = f\"{base_name}_{r+1},{c+1}.bmp\"\n",
    "            cv2.imwrite(os.path.join(array_dir, fname), tile)\n",
    "            tiles.append({'row': r+1, 'col': c+1, 'center': (cx, cy)})\n",
    "    \n",
    "    return img, tiles, (x_spacing, y_spacing)\n",
    "\n",
    "# Process all arrays\n",
    "arrays = [\"Array_1Crop.bmp\", \"Array_2Crop.bmp\", \"Array_3Crop.bmp\"]\n",
    "array_images = {}\n",
    "\n",
    "for arr in arrays:\n",
    "    arr_path = BASE_DIR / arr\n",
    "    if arr_path.exists():\n",
    "        img, tiles, spacing = segment_array(str(arr_path), str(OUTPUT_DIR), show_grid=False)\n",
    "        array_images[arr.replace('.bmp', '')] = img\n",
    "        print(f\"{arr}: Extracted {len(tiles)} tiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: Segmentation Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create segmentation overview figure\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "gs = gridspec.GridSpec(1, 4, width_ratios=[1, 1, 1, 0.4], wspace=0.15)\n",
    "\n",
    "for idx, (name, img) in enumerate(array_images.items()):\n",
    "    ax = fig.add_subplot(gs[idx])\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(img_rgb)\n",
    "    \n",
    "    # Draw grid overlay\n",
    "    H, W = img.shape[:2]\n",
    "    for i in range(22):\n",
    "        ax.axhline(y=i * H/21, color='lime', linewidth=0.3, alpha=0.5)\n",
    "        ax.axvline(x=i * W/21, color='lime', linewidth=0.3, alpha=0.5)\n",
    "    \n",
    "    ax.set_title(f'{name.replace(\"Crop\", \"\")}\\n(21 x 21 = 441 atoms)', fontsize=11)\n",
    "    ax.axis('off')\n",
    "\n",
    "# Info panel\n",
    "ax_info = fig.add_subplot(gs[3])\n",
    "ax_info.axis('off')\n",
    "info_text = (\n",
    "    \"Segmentation\\nStatistics\\n\"\n",
    "    \"----------\\n\"\n",
    "    f\"Arrays: 3\\n\"\n",
    "    f\"Grid: 21 x 21\\n\"\n",
    "    f\"Atoms/array: 441\\n\"\n",
    "    f\"Total atoms: 1323\\n\"\n",
    "    f\"Tile size: 64x64 px\"\n",
    ")\n",
    "ax_info.text(0.1, 0.5, info_text, transform=ax_info.transAxes, \n",
    "             fontsize=11, verticalalignment='center', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='#f0f0f0', edgecolor='gray'))\n",
    "\n",
    "plt.suptitle('Automated Metasurface Array Segmentation Pipeline', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.savefig(FIGURES_DIR / 'fig1_segmentation_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_gray):\n",
    "    \"\"\"Extract comprehensive feature vector from meta-atom image.\"\"\"\n",
    "    # Gradient features\n",
    "    sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    \n",
    "    # Intensity features\n",
    "    mean_intensity = np.mean(img_gray)\n",
    "    std_intensity = np.std(img_gray)\n",
    "    \n",
    "    # Binary segmentation\n",
    "    img_bin = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                     cv2.THRESH_BINARY_INV, 21, 3)\n",
    "    \n",
    "    # Contour features\n",
    "    contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    area, perimeter, solidity, circularity = 0, 0, 0, 0\n",
    "    hu_moments = np.zeros(7)\n",
    "    \n",
    "    if contours:\n",
    "        cnt = max(contours, key=cv2.contourArea)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        \n",
    "        hull = cv2.convexHull(cnt)\n",
    "        hull_area = cv2.contourArea(hull)\n",
    "        solidity = area / hull_area if hull_area > 0 else 0\n",
    "        circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter > 0 else 0\n",
    "        \n",
    "        mask = np.zeros_like(img_bin)\n",
    "        cv2.drawContours(mask, [cnt], -1, 255, -1)\n",
    "        hu_moments = cv2.HuMoments(cv2.moments(mask)).flatten()\n",
    "    \n",
    "    return {\n",
    "        'mean_intensity': mean_intensity,\n",
    "        'std_intensity': std_intensity,\n",
    "        'max_gradient': np.max(mag),\n",
    "        'mean_gradient': np.mean(mag),\n",
    "        'area': area,\n",
    "        'solidity': solidity,\n",
    "        'circularity': circularity,\n",
    "        'hu_moments': hu_moments,\n",
    "        'laplacian_var': cv2.Laplacian(img_gray, cv2.CV_64F).var()\n",
    "    }\n",
    "\n",
    "def load_all_tiles():\n",
    "    \"\"\"Load all tiles and extract features.\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for array_name in [\"Array_1Crop\", \"Array_2Crop\", \"Array_3Crop\"]:\n",
    "        array_dir = OUTPUT_DIR / array_name\n",
    "        if not array_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        for fpath in array_dir.glob(\"*.bmp\"):\n",
    "            img = cv2.imread(str(fpath), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            fname = fpath.stem\n",
    "            try:\n",
    "                coords = fname.split('_')[-1]\n",
    "                row, col = map(int, coords.split(','))\n",
    "            except:\n",
    "                row, col = -1, -1\n",
    "            \n",
    "            features = extract_features(img)\n",
    "            all_data.append({\n",
    "                'array': array_name,\n",
    "                'filename': fpath.name,\n",
    "                'filepath': str(fpath),\n",
    "                'row': row, 'col': col,\n",
    "                'image': img,\n",
    "                **features\n",
    "            })\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# Load data\n",
    "tile_data = load_all_tiles()\n",
    "print(f\"Total meta-atoms loaded: {len(tile_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_matrix(tile_data):\n",
    "    \"\"\"Construct feature matrix for clustering.\"\"\"\n",
    "    features = []\n",
    "    for t in tile_data:\n",
    "        row = [\n",
    "            t['mean_intensity'], t['std_intensity'],\n",
    "            t['max_gradient'], t['mean_gradient'],\n",
    "            t['area'], t['solidity'], t['circularity'],\n",
    "            t['laplacian_var']\n",
    "        ]\n",
    "        hu_log = -np.sign(t['hu_moments']) * np.log10(np.abs(t['hu_moments']) + 1e-10)\n",
    "        row.extend(hu_log)\n",
    "        features.append(row)\n",
    "    \n",
    "    X = np.nan_to_num(np.array(features), nan=0, posinf=0, neginf=0)\n",
    "    return X\n",
    "\n",
    "X_raw = build_feature_matrix(tile_data)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Feature matrix: {X_raw.shape}\")\n",
    "print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: Feature Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE embedding\n",
    "print(\"Computing t-SNE embedding...\")\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X_pca)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# PCA scatter\n",
    "ax = axes[0]\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=X_raw[:, 0], cmap='viridis', \n",
    "                      alpha=0.6, s=15, edgecolors='none')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('PCA Projection\\n(colored by intensity)')\n",
    "plt.colorbar(scatter, ax=ax, label='Mean Intensity')\n",
    "\n",
    "# t-SNE scatter\n",
    "ax = axes[1]\n",
    "scatter = ax.scatter(X_tsne[:, 0], X_tsne[:, 1], c=X_raw[:, 4], cmap='plasma',\n",
    "                      alpha=0.6, s=15, edgecolors='none')\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_title('t-SNE Embedding\\n(colored by area)')\n",
    "plt.colorbar(scatter, ax=ax, label='Area')\n",
    "\n",
    "# Feature correlations\n",
    "ax = axes[2]\n",
    "feature_names = ['Intensity', 'Std', 'MaxGrad', 'MeanGrad', 'Area', 'Solidity', 'Circular', 'Laplacian']\n",
    "corr_matrix = np.corrcoef(X_raw[:, :8].T)\n",
    "im = ax.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(8))\n",
    "ax.set_yticks(range(8))\n",
    "ax.set_xticklabels(feature_names, rotation=45, ha='right', fontsize=8)\n",
    "ax.set_yticklabels(feature_names, fontsize=8)\n",
    "ax.set_title('Feature Correlation Matrix')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "plt.suptitle('Feature Space Analysis', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig2_feature_space.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. K-Means Clustering Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3: Optimal K Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(2, 10)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X_pca)\n",
    "    inertias.append(km.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_pca, labels))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Elbow plot\n",
    "ax = axes[0]\n",
    "ax.plot(k_range, inertias, 'o-', color='#2c3e50', linewidth=2, markersize=8)\n",
    "ax.axvline(x=4, color='#e74c3c', linestyle='--', linewidth=2, label='K=4')\n",
    "ax.set_xlabel('Number of Clusters (K)')\n",
    "ax.set_ylabel('Inertia (Within-Cluster SS)')\n",
    "ax.set_title('Elbow Method')\n",
    "ax.legend()\n",
    "ax.set_xticks(range(2, 10))\n",
    "\n",
    "# Silhouette plot\n",
    "ax = axes[1]\n",
    "ax.plot(k_range, silhouettes, 's-', color='#27ae60', linewidth=2, markersize=8)\n",
    "ax.axvline(x=4, color='#e74c3c', linestyle='--', linewidth=2, label='K=4')\n",
    "ax.set_xlabel('Number of Clusters (K)')\n",
    "ax.set_ylabel('Silhouette Score')\n",
    "ax.set_title('Silhouette Analysis')\n",
    "ax.legend()\n",
    "ax.set_xticks(range(2, 10))\n",
    "\n",
    "# Combined score\n",
    "ax = axes[2]\n",
    "# Normalize both metrics\n",
    "inertias_norm = (np.array(inertias) - min(inertias)) / (max(inertias) - min(inertias))\n",
    "silhouettes_norm = np.array(silhouettes)\n",
    "combined = silhouettes_norm - 0.3 * inertias_norm  # Weight silhouette more\n",
    "\n",
    "ax.bar(k_range, combined, color=[CLUSTER_COLORS[i % len(CLUSTER_COLORS)] for i in range(len(k_range))],\n",
    "       edgecolor='black', linewidth=0.5)\n",
    "ax.axhline(y=combined[2], color='#e74c3c', linestyle='--', linewidth=2)  # K=4 line\n",
    "ax.set_xlabel('Number of Clusters (K)')\n",
    "ax.set_ylabel('Combined Score')\n",
    "ax.set_title('Optimal K Selection')\n",
    "ax.set_xticks(range(2, 10))\n",
    "\n",
    "best_k = list(k_range)[np.argmax(silhouettes)]\n",
    "print(f\"Optimal K by silhouette: {best_k}\")\n",
    "\n",
    "plt.suptitle('K-Means: Optimal Cluster Selection', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig3_optimal_k.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final K-Means with K=4\n",
    "K = 4\n",
    "kmeans = KMeans(n_clusters=K, random_state=42, n_init=20)\n",
    "labels = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Store cluster labels\n",
    "for i, tile in enumerate(tile_data):\n",
    "    tile['cluster'] = labels[i]\n",
    "\n",
    "# Cluster statistics\n",
    "cluster_counts = Counter(labels)\n",
    "print(\"\\nCluster Distribution:\")\n",
    "for c in range(K):\n",
    "    print(f\"  Cluster {c}: {cluster_counts[c]} atoms ({cluster_counts[c]/len(labels)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nSilhouette Score: {silhouette_score(X_pca, labels):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4: Clustering Results in Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# t-SNE with clusters\n",
    "ax = axes[0]\n",
    "for c in range(K):\n",
    "    mask = labels == c\n",
    "    ax.scatter(X_tsne[mask, 0], X_tsne[mask, 1], c=CLUSTER_COLORS[c], \n",
    "               label=f'Cluster {c} (n={mask.sum()})', alpha=0.7, s=20, edgecolors='white', linewidth=0.3)\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "ax.set_title('t-SNE Clustering')\n",
    "ax.legend(loc='best', framealpha=0.9)\n",
    "\n",
    "# PCA with clusters and centroids\n",
    "ax = axes[1]\n",
    "for c in range(K):\n",
    "    mask = labels == c\n",
    "    ax.scatter(X_pca[mask, 0], X_pca[mask, 1], c=CLUSTER_COLORS[c], \n",
    "               label=f'Cluster {c}', alpha=0.5, s=15)\n",
    "# Plot centroids\n",
    "centroids_pca = kmeans.cluster_centers_\n",
    "ax.scatter(centroids_pca[:, 0], centroids_pca[:, 1], c='black', marker='X', \n",
    "           s=200, edgecolors='white', linewidth=2, label='Centroids', zorder=10)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title('PCA Clustering with Centroids')\n",
    "ax.legend(loc='best', framealpha=0.9)\n",
    "\n",
    "# Silhouette analysis\n",
    "ax = axes[2]\n",
    "silhouette_vals = silhouette_samples(X_pca, labels)\n",
    "y_lower = 10\n",
    "\n",
    "for c in range(K):\n",
    "    cluster_silhouette = silhouette_vals[labels == c]\n",
    "    cluster_silhouette.sort()\n",
    "    size_cluster = cluster_silhouette.shape[0]\n",
    "    y_upper = y_lower + size_cluster\n",
    "    \n",
    "    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette,\n",
    "                      facecolor=CLUSTER_COLORS[c], edgecolor=CLUSTER_COLORS[c], alpha=0.7)\n",
    "    ax.text(-0.05, y_lower + 0.5 * size_cluster, str(c), fontsize=10, fontweight='bold')\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax.axvline(x=silhouette_score(X_pca, labels), color='red', linestyle='--', linewidth=2, label='Avg Score')\n",
    "ax.set_xlabel('Silhouette Coefficient')\n",
    "ax.set_ylabel('Cluster')\n",
    "ax.set_title('Silhouette Plot')\n",
    "ax.set_xlim([-0.1, 1])\n",
    "ax.legend()\n",
    "\n",
    "plt.suptitle('K-Means Clustering Results (K=4)', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig4_clustering_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cluster Sample Gallery\n",
    "\n",
    "Representative examples from each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5: Cluster Sample Grid (Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cluster_gallery(tile_data, n_samples=20):\n",
    "    \"\"\"Display large gallery of samples from each cluster.\"\"\"\n",
    "    n_clusters = K\n",
    "    n_cols = n_samples\n",
    "    \n",
    "    fig, axes = plt.subplots(n_clusters, n_cols, figsize=(n_cols * 0.8, n_clusters * 1.2))\n",
    "    \n",
    "    for c in range(n_clusters):\n",
    "        cluster_tiles = [t for t in tile_data if t['cluster'] == c]\n",
    "        np.random.shuffle(cluster_tiles)\n",
    "        samples = cluster_tiles[:n_samples]\n",
    "        \n",
    "        for j in range(n_cols):\n",
    "            ax = axes[c, j]\n",
    "            if j < len(samples):\n",
    "                ax.imshow(samples[j]['image'], cmap='gray')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Row label\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f'C{c}\\n(n={len(cluster_tiles)})', fontsize=10, fontweight='bold',\n",
    "                             rotation=0, labelpad=30, va='center', color=CLUSTER_COLORS[c])\n",
    "    \n",
    "    plt.suptitle('Cluster Sample Gallery: 20 Random Samples per Cluster', fontsize=14, fontweight='bold', y=1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / 'fig5_cluster_gallery.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "show_cluster_gallery(tile_data, n_samples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 6: Extended Cluster Examples (50 per cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_extended_gallery(tile_data, cluster_id, n_samples=50):\n",
    "    \"\"\"Show many examples from a single cluster.\"\"\"\n",
    "    cluster_tiles = [t for t in tile_data if t['cluster'] == cluster_id]\n",
    "    np.random.shuffle(cluster_tiles)\n",
    "    samples = cluster_tiles[:n_samples]\n",
    "    \n",
    "    n_cols = 10\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < len(samples):\n",
    "            ax.imshow(samples[i]['image'], cmap='gray')\n",
    "            ax.set_title(f\"{samples[i]['row']},{samples[i]['col']}\", fontsize=6, pad=1)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Cluster {cluster_id}: {len(cluster_tiles)} Total Atoms ({n_samples} shown)',\n",
    "                 fontsize=14, fontweight='bold', color=CLUSTER_COLORS[cluster_id], y=1.01)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Show each cluster\n",
    "for c in range(K):\n",
    "    fig = show_extended_gallery(tile_data, c, n_samples=50)\n",
    "    fig.savefig(FIGURES_DIR / f'fig6_cluster{c}_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Spatial Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 7: Cluster Heatmaps on Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_map(tile_data, array_name):\n",
    "    \"\"\"Create spatial heatmap of clusters on array grid.\"\"\"\n",
    "    grid = np.full((21, 21), -1)\n",
    "    \n",
    "    for tile in tile_data:\n",
    "        if tile['array'] == array_name and tile['row'] > 0 and tile['col'] > 0:\n",
    "            grid[tile['row']-1, tile['col']-1] = tile['cluster']\n",
    "    \n",
    "    return grid\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "# Custom colormap for clusters\n",
    "cmap = LinearSegmentedColormap.from_list('clusters', CLUSTER_COLORS[:K], N=K)\n",
    "\n",
    "for idx, array_name in enumerate([\"Array_1Crop\", \"Array_2Crop\", \"Array_3Crop\"]):\n",
    "    ax = axes[idx]\n",
    "    grid = create_cluster_map(tile_data, array_name)\n",
    "    \n",
    "    im = ax.imshow(grid, cmap=cmap, vmin=0, vmax=K-1)\n",
    "    ax.set_title(f'{array_name.replace(\"Crop\", \"\")}', fontsize=12)\n",
    "    ax.set_xlabel('Column')\n",
    "    ax.set_ylabel('Row')\n",
    "    \n",
    "    # Grid lines\n",
    "    ax.set_xticks(np.arange(-0.5, 21, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, 21, 1), minor=True)\n",
    "    ax.grid(which='minor', color='white', linewidth=0.5, alpha=0.5)\n",
    "    ax.tick_params(which='minor', size=0)\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(im, ax=axes, shrink=0.6, pad=0.02)\n",
    "cbar.set_ticks(np.arange(K))\n",
    "cbar.set_ticklabels([f'C{i}' for i in range(K)])\n",
    "\n",
    "plt.suptitle('Spatial Distribution of Defect Clusters', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.savefig(FIGURES_DIR / 'fig7_spatial_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 8: Cluster Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "features_to_plot = [\n",
    "    ('mean_intensity', 'Mean Intensity'),\n",
    "    ('area', 'Contour Area'),\n",
    "    ('solidity', 'Solidity'),\n",
    "    ('circularity', 'Circularity'),\n",
    "    ('max_gradient', 'Max Gradient'),\n",
    "    ('std_intensity', 'Intensity Std Dev')\n",
    "]\n",
    "\n",
    "for idx, (feat_key, feat_name) in enumerate(features_to_plot):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    data_by_cluster = []\n",
    "    for c in range(K):\n",
    "        cluster_vals = [t[feat_key] for t in tile_data if t['cluster'] == c]\n",
    "        data_by_cluster.append(cluster_vals)\n",
    "    \n",
    "    bp = ax.boxplot(data_by_cluster, patch_artist=True, widths=0.6)\n",
    "    \n",
    "    for patch, color in zip(bp['boxes'], CLUSTER_COLORS[:K]):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    ax.set_xticklabels([f'C{c}' for c in range(K)])\n",
    "    ax.set_xlabel('Cluster')\n",
    "    ax.set_ylabel(feat_name)\n",
    "    ax.set_title(feat_name)\n",
    "\n",
    "plt.suptitle('Feature Distributions by Cluster', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig8_feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 9: Pipeline Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = gridspec.GridSpec(3, 4, height_ratios=[1.2, 1, 1], hspace=0.3, wspace=0.25)\n",
    "\n",
    "# Row 1: Pipeline overview\n",
    "ax_pipe = fig.add_subplot(gs[0, :])\n",
    "ax_pipe.axis('off')\n",
    "\n",
    "# Draw pipeline boxes\n",
    "steps = [\n",
    "    ('Input\\nArrays', '#3498db', '3 BMP\\nImages'),\n",
    "    ('Segmentation', '#2ecc71', '1323\\nTiles'),\n",
    "    ('Feature\\nExtraction', '#f39c12', '15 Features\\nper tile'),\n",
    "    ('K-Means\\nClustering', '#9b59b6', '4 Clusters'),\n",
    "    ('Classification', '#e74c3c', 'Defect\\nLabels')\n",
    "]\n",
    "\n",
    "for i, (label, color, detail) in enumerate(steps):\n",
    "    x = 0.1 + i * 0.18\n",
    "    rect = plt.Rectangle((x, 0.3), 0.14, 0.4, transform=ax_pipe.transAxes,\n",
    "                          facecolor=color, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "    ax_pipe.add_patch(rect)\n",
    "    ax_pipe.text(x + 0.07, 0.5, label, transform=ax_pipe.transAxes,\n",
    "                 ha='center', va='center', fontsize=11, fontweight='bold', color='white')\n",
    "    ax_pipe.text(x + 0.07, 0.2, detail, transform=ax_pipe.transAxes,\n",
    "                 ha='center', va='center', fontsize=9, style='italic')\n",
    "    \n",
    "    if i < len(steps) - 1:\n",
    "        ax_pipe.annotate('', xy=(x + 0.16, 0.5), xytext=(x + 0.14, 0.5),\n",
    "                         xycoords='axes fraction', textcoords='axes fraction',\n",
    "                         arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "ax_pipe.set_title('High-Throughput Meta-Atom Defect Classification Pipeline', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Row 2: Cluster pie chart and bar chart\n",
    "ax_pie = fig.add_subplot(gs[1, 0])\n",
    "sizes = [cluster_counts[c] for c in range(K)]\n",
    "explode = [0.02] * K\n",
    "ax_pie.pie(sizes, explode=explode, labels=[f'C{c}' for c in range(K)], colors=CLUSTER_COLORS[:K],\n",
    "           autopct='%1.1f%%', shadow=False, startangle=90)\n",
    "ax_pie.set_title('Cluster Distribution')\n",
    "\n",
    "ax_bar = fig.add_subplot(gs[1, 1])\n",
    "ax_bar.bar(range(K), sizes, color=CLUSTER_COLORS[:K], edgecolor='black', linewidth=1)\n",
    "ax_bar.set_xticks(range(K))\n",
    "ax_bar.set_xticklabels([f'C{c}' for c in range(K)])\n",
    "ax_bar.set_ylabel('Count')\n",
    "ax_bar.set_title('Cluster Counts')\n",
    "for i, v in enumerate(sizes):\n",
    "    ax_bar.text(i, v + 10, str(v), ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Per-array breakdown\n",
    "ax_stacked = fig.add_subplot(gs[1, 2:])\n",
    "array_names = [\"Array_1Crop\", \"Array_2Crop\", \"Array_3Crop\"]\n",
    "bottom = np.zeros(3)\n",
    "\n",
    "for c in range(K):\n",
    "    counts = [sum(1 for t in tile_data if t['array'] == arr and t['cluster'] == c) for arr in array_names]\n",
    "    ax_stacked.bar(range(3), counts, bottom=bottom, label=f'C{c}', color=CLUSTER_COLORS[c])\n",
    "    bottom += counts\n",
    "\n",
    "ax_stacked.set_xticks(range(3))\n",
    "ax_stacked.set_xticklabels(['Array 1', 'Array 2', 'Array 3'])\n",
    "ax_stacked.set_ylabel('Count')\n",
    "ax_stacked.set_title('Cluster Distribution by Array')\n",
    "ax_stacked.legend(loc='upper right')\n",
    "\n",
    "# Row 3: Sample images from each cluster\n",
    "for c in range(K):\n",
    "    ax = fig.add_subplot(gs[2, c])\n",
    "    cluster_tiles = [t for t in tile_data if t['cluster'] == c]\n",
    "    np.random.shuffle(cluster_tiles)\n",
    "    \n",
    "    # Create montage of 16 samples (4x4)\n",
    "    montage = np.zeros((4*64, 4*64), dtype=np.uint8)\n",
    "    for i in range(min(16, len(cluster_tiles))):\n",
    "        img = cluster_tiles[i]['image']\n",
    "        img_resized = cv2.resize(img, (64, 64))\n",
    "        row, col = i // 4, i % 4\n",
    "        montage[row*64:(row+1)*64, col*64:(col+1)*64] = img_resized\n",
    "    \n",
    "    ax.imshow(montage, cmap='gray')\n",
    "    ax.set_title(f'Cluster {c}\\n(n={len(cluster_tiles)})', color=CLUSTER_COLORS[c], fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add colored border\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_color(CLUSTER_COLORS[c])\n",
    "        spine.set_linewidth(4)\n",
    "\n",
    "plt.savefig(FIGURES_DIR / 'fig9_pipeline_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Cluster Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CLUSTER STATISTICS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Cluster':<10} {'Count':>8} {'%':>8} {'Intensity':>12} {'Area':>10} {'Solidity':>10} {'Circular':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for c in range(K):\n",
    "    cluster_tiles = [t for t in tile_data if t['cluster'] == c]\n",
    "    n = len(cluster_tiles)\n",
    "    pct = n / len(tile_data) * 100\n",
    "    \n",
    "    mean_int = np.mean([t['mean_intensity'] for t in cluster_tiles])\n",
    "    mean_area = np.mean([t['area'] for t in cluster_tiles])\n",
    "    mean_sol = np.mean([t['solidity'] for t in cluster_tiles])\n",
    "    mean_circ = np.mean([t['circularity'] for t in cluster_tiles])\n",
    "    \n",
    "    print(f\"C{c:<9} {n:>8} {pct:>7.1f}% {mean_int:>12.1f} {mean_area:>10.1f} {mean_sol:>10.3f} {mean_circ:>10.3f}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'TOTAL':<10} {len(tile_data):>8}\")\n",
    "print(f\"\\nSilhouette Score: {silhouette_score(X_pca, labels):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Export to CSV\n",
    "csv_path = OUTPUT_DIR / 'kmeans_clustering_results.csv'\n",
    "fieldnames = ['array', 'filename', 'row', 'col', 'cluster', 'mean_intensity', 'area', \n",
    "              'solidity', 'circularity', 'max_gradient', 'filepath']\n",
    "\n",
    "with open(csv_path, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')\n",
    "    writer.writeheader()\n",
    "    for tile in tile_data:\n",
    "        writer.writerow(tile)\n",
    "\n",
    "print(f\"Results exported to: {csv_path}\")\n",
    "print(f\"Figures saved to: {FIGURES_DIR}\")\n",
    "print(f\"\\nGenerated figures:\")\n",
    "for f in sorted(FIGURES_DIR.glob('*.png')):\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Throughput Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark throughput\n",
    "print(\"Throughput Benchmarking...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Time feature extraction\n",
    "sample_tiles = tile_data[:100]\n",
    "start = time.time()\n",
    "for tile in sample_tiles:\n",
    "    _ = extract_features(tile['image'])\n",
    "feat_time = time.time() - start\n",
    "feat_per_sec = 100 / feat_time\n",
    "\n",
    "# Time clustering\n",
    "start = time.time()\n",
    "_ = KMeans(n_clusters=4, random_state=42, n_init=10).fit_predict(X_pca)\n",
    "cluster_time = time.time() - start\n",
    "\n",
    "total_atoms = len(tile_data)\n",
    "estimated_total_time = (total_atoms / 100) * feat_time + cluster_time\n",
    "\n",
    "print(f\"Feature extraction: {feat_per_sec:.1f} atoms/second\")\n",
    "print(f\"K-Means clustering: {cluster_time:.3f} seconds for {total_atoms} atoms\")\n",
    "print(f\"\\nTotal pipeline time: {estimated_total_time:.2f} seconds\")\n",
    "print(f\"Throughput: {total_atoms / estimated_total_time:.1f} atoms/second\")\n",
    "print(f\"\\nScalability projection:\")\n",
    "print(f\"  10,000 atoms: ~{10000 / feat_per_sec + cluster_time:.1f} seconds\")\n",
    "print(f\"  100,000 atoms: ~{100000 / feat_per_sec + cluster_time * 10:.1f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
